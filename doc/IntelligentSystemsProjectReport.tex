% !TeX spellcheck = en_US
\documentclass[a4paper]{report}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{lipsum}
\usepackage{verbatim}
\usepackage[table,xcdraw]{xcolor}
\geometry{a4paper,top=2.5cm,bottom=2.5cm,left=3cm,right=3cm,%
	heightrounded,bindingoffset=5mm}

\usepackage{color}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}

\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}


\usepackage{color}
\usepackage{listings}
\lstset{ %
	language=Matlab,                % choose the language of the code
	basicstyle=\footnotesize,       % the size of the fonts that are used for the code
	numbers=left,                   % where to put the line-numbers
	numberstyle=\footnotesize,      % the size of the fonts that are used for the line-numbers
	stepnumber=1,                   % the step between two line-numbers. If it is 1 each line will be numbered
	numbersep=5pt,                  % how far the line-numbers are from the code
	backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
	showspaces=false,               % show spaces adding particular underscores
	showstringspaces=false,         % underline spaces within strings
	showtabs=false,                 % show tabs within strings adding particular underscores
	frame=single,           % adds a frame around the code
	tabsize=2,          % sets default tabsize to 2 spaces
	captionpos=b,           % sets the caption-position to bottom
	breaklines=true,        % sets automatic line breaking
	breakatwhitespace=false,    % sets if automatic breaks should only happen at whitespace
	escapeinside={\%*}{*)}          % if you want to add a comment within your code
}





\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\begin{document}
	\begin{titlepage}
		\begin{center}
			
			% Top 
			\includegraphics[width=0.45\textwidth]{img/unipi.png}~\\[2.5cm]
			
			
			% Title
			\HRule \\[0.4cm]
			{ \LARGE 
				\Huge\textbf{Intelligent Systems Project Report}\\[0.5cm]
				\LARGE\textit{Author:} \\[0.1cm]
				Francesco Iemma \\[0.1cm]
				%\emph{Francesco Iemma}\\[0.4cm]
			}
			\HRule \\[1.5cm]
			
			
			
			% Author
			{ \Large
			%	\textit{Author:} \\[0.1cm]
			%	Francesco Iemma \\[0.1cm]
			}
			
			\vfill
			
			\textsc{\large M.Sc. in Computer Engineering}\\[0.4cm]
			
			
			% Bottom
			{\large Academic Year 2020/21}
			
		\end{center}
	\end{titlepage}
	
	
	\tableofcontents
	
\chapter*{Introduction}
	The tasks performed in this project are the following:
	\begin{itemize}
		\item \textit{3.1} "Design and develop two MLP artificial neural networks that accurately estimate a person's valence and arousal, respectively" and "two RBF networks that do the same thing as the MPLPs"
		
		\item \textit{3.3} "Design and develop a fuzzy inference system to fix the deficiencies in the arousal dimension"
		
		\item \textit{4.2} "Fine-tune a pretrained CNN" to  obtain a "convolutional neural network (CNN) that accurately classifies a person's emotion, based on facial expression."
	\end{itemize}

	\noindent The dataset at our disposal are two, one for tasks \textit{3.1} and \textit{3.3} and another one for task \textit{4.2}.
	\noindent For what concern the first dataset, i.e. the one with biomedical signals for estimate arousal and valence, it is important to perform a cleaning of the data in order to obtain better performance for the neural networks that will be trained on it. This process, which is performed by the script \texttt{/matlab/data.m} is explained in the \autoref{chap: dataCleaning}. 
	
	\noindent After this chapter for each task is dedicated a chapter in which are explained the choices done and the results obtained in terms of performance.
	
\chapter{Data Cleaning}
	\label{chap: dataCleaning}
	\noindent In this chapter we will see the data cleaning procedure performed in order to obtain better performance for the NNs. The steps done are:
	\begin{itemize}
		\item Remove non numeric values
		\item Remove outliers
		\item Balance the data among the different values of arousal and valence
		\item Features selection
	\end{itemize}
	\noindent All the procedure is contained in the file \texttt{/matlab/data.m}. The first two steps are performed thanks two matlab functions:
	\begin{itemize}
		\item \texttt{isinf(A)} that given a matrix returns a logic matrix is indicated if the correspondent element of the input matrix are infinite ($1$) or not ($0$) 
		
		\item \texttt{rmoutliers(dataset, method)} that given a dataset remove the outliers found using the method specified in input that is 'median' by default (i.e. "Outliers are defined as elements more than three scaled MAD from the median. The scaled MAD is defined as $c\times median(abs(A-median(A))$")
	\end{itemize} 
	
	\noindent Then after the first two steps there are the most interesting part: data balancing and features selection.
	
	\newpage
	\section{Data Balancing}
	\noindent The dataset is composed by samples and each sample contains biomedical signals: to each set of biomedical signals (that we will call \textit{features}) correspond a value for arousal and a value for valence. The possible values are 7 ($1,\; 2.\bar3,\; 3.\bar6,\; 5,\; 6.\bar3,\; 7.\bar6,\; 9$), thus we can divide the dataset according 7 class for arousal and valence. The distribution of the samples among the classes is represented in the histograms in figure \ref{beforeBalancingArousal} and \ref{beforeBalancingValence}.
	
	\begin{figure}[htpb]
		\centering
		\includegraphics[scale=0.7]{img/beforeBalancingArousal.png}
		\caption{Classes Distribution For Arousal Before Balancing}
		\label{beforeBalancingArousal}
	\end{figure}  

	\begin{figure}[htpb]
		\centering
		\includegraphics[scale=0.7]{img/beforeBalancingValence.png}
		\caption{Classes Distribution For Valence Before Balancing}
		\label{beforeBalancingValence}
	\end{figure}


\noindent As we can see the samples are heavily unbalanced, for this reason an algorithm to balance the data has been used. The algorithm is based on the concepts of undersampling, oversampling and data augmentation.

\noindent The steps are the following:
\begin{enumerate}
	\item I augment the samples that belong to the majority class of arousal 
	 and don't belong to the majority class of valence and viceversa (i.e. the samples that 
	 belong to the majority class of valence and don't belong to the minority
	 class of arousal).
	 
	 \item I remove the samples that belong to the majority class of 
	 arousal and don't belong to the minority class of valence and viceversa (i.e. the
	 samples that belong to the majority class of valence and don't belong to
	 the minority class of arousal).
	
	 \item I repeat steps 1 and 2 for a $n=40$ ($40$ after some experiments this is the number that gives the best results) times and for each repetition I compute the new majority and minority class both for arousal and valence.
	 
	 \item After the end of the repetitions I perform an undersampling on the first class because it is unbalanced for what concern the valence. Thus I remove some samples from this class, after some experiments removing $30$ samples results in a balanced distribution for both arousal and valence.
\end{enumerate}

\noindent At the end of this procedure the data are balanced as we can see in figure \ref{afterBalancingArousal} and \ref{afterBalancingValence}.

	\begin{figure}[htbp]
		\centering
		\includegraphics[scale=0.7]{img/afterBalancingArousal.png}
		\caption{Classes Distribution For Arousal After Balancing}
		\label{afterBalancingArousal}
	\end{figure}  
	
		\begin{figure}[htbp]
		\centering
		\includegraphics[scale=0.7]{img/afterBalancingValence.png}
		\caption{Classes Distribution For Valence After Balancing}
		\label{afterBalancingValence}
	\end{figure}
	
	\section{Features Selection}
	\noindent Before the features selection is necessary to divide the data in two set: one for training and one for test. This is very important because if we use all the data to perform feature selection we have a bias because the test data have been already seen by the net.
	
	\noindent Thus after the extraction of the holdout partition we perform x CAMBIARE times \texttt{sequentialfs} for arousal and x time for valence. Then we select the first \texttt{FEATURES\_TO\_SELECT} (constant set at the beginning of the script) features that appear most times in the different runs of sequentialfs, this operation is performed separately for arousal and valence.
	
	\noindent At the end we save the data obtained into three \texttt{.mat} files:
	\begin{itemize}
		\item \texttt{/matlab/data/biomedical\_signals/dataset\_cleaned.mat}
		
		\noindent It contains the entire dataset without infinite values, outliers and with balanced class distribution.
		\item \texttt{/matlab/data/biomedical\_signals/training\_data.mat}
		
		\noindent It contains a \texttt{struct} with the training input (only the selected features) and the correspondent target output.
		
		\item \texttt{/matlab/data/biomedical\_signals/test\_data.mat}
		
		\noindent It contains a \texttt{struct} with the test input (only the selected features) and the correspondent expected output.
	\end{itemize}
	
\chapter{Neural Networks}
	\noindent In this chapter we will see two types of neural networks that resolve the same problem, that is to estimate the values of arousal and valence given a set of biomedical signals.	
	\section{Fitnet}
	\section{RBF}
	
	\chapter{Fuzzy Inference System}
	
\chapter{Convolutional Neural Networks}
	\noindent In this chapter is discussed the development and the training of a CNN based on the pre-trained AlexNet which has the aim of classifying facial expressions. The possible classes are four:
	\begin{itemize}
		\item Happiness
		\item Anger
		\item Disgust
		\item Fear
	\end{itemize} 
	\noindent Two CNNs have been developed (both are based on AlexNet). The first one is able to classify images in two classes (happiness and anger), instead the second one is able to classify images in all of the four classes.
	
	\section{CNN For 2-Classes Classification Problem}
	\noindent The matlab code for this CNN is in the file \texttt{/matlab/cnn\_2classes.m}. Due to the fact that the images of happiness and the ones for anger are very different it is possible to obtain good result (accuracy equal to 82.67\%) without a proper selection of the images.
	\noindent In fact as first experiment 500 images for each class are selected at random from the dataset. This experiment return the results shown in figure \ref{img: trainingCnnTwoClasses}:
	
	\begin{figure}[htbp]
		\centering
		\includegraphics[scale=0.31]{img/trainingCnnTwoClasses.png}
		\caption{First experiment: no images selection}
		\label{img: trainingCnnTwoClasses}
	\end{figure}

	\noindent Then a selection of the images has been performed and from the 500 images only 300 have been selected. The selection consist in the removal of the images with ambiguous facial expressions. After this selection the results in figure \ref{img: trainingCnnTwoClassesAfterSelection} are obtained.
	
	\begin{figure}[htbp]
		\centering
		\includegraphics[scale=0.31]{img/trainingCnnTwoClasses_afterSelection.png}
		\caption{Second experiment: after selection}
		\label{img: trainingCnnTwoClassesAfterSelection}
	\end{figure}

	\noindent Thanks to the selection of the images the validation accuracy has increased by $\approx 6\%$: from 82.67\% to 88.33\%.
	 
	\section{CNN For 4-Classes Classification Problem}
	\noindent The matlab code for this CNN is in the file \texttt{/matlab/cnn\_4classes.m}. As in the previous case two experiments have been performed, the first one with 500 images per class selected at random, the second one with 300 images selected removing the images classified wrong or with ambiguous facial expressions.
	
	\noindent The results for the experiments are respectively in the figures \ref{img: trainingCnnFourClasses} and \ref{img: trainingCnnFourClassesAfterSelection}.
	
	\noindent Analyzing the two results it is possible to see that, thanks to the selection, we have improved the accuracy from 58.17\% to 63.61\% that can be considered a reasonable result for a classification problem with 4 classes.
	
	\begin{figure}[htbp]
		\centering
		\includegraphics[scale=0.31]{img/trainingCnnFourClasses.png}
		\caption{First experiment: no images selection}
		\label{img: trainingCnnFourClasses}
	\end{figure}
	
	\begin{figure}[htbp]
		\centering
		\includegraphics[scale=0.31]{img/trainingCnnFourClasses_afterSelection.png}
		\caption{Second experiment: after images selection}
		\label{img: trainingCnnFourClassesAfterSelection}
	\end{figure}
	

	
	\section{Design Choices}
	\noindent The dataset of images is very huge, but in order to maintain a reasonable training time only 500 images have been selected at random for each classes, then in order to improve performance a selection has been performed reducing this number to 300 images per class.
	
	\noindent In all experiments the images used in training have been augmented:
	\begin{lstlisting}[language=Matlab]
	pixelRange = [-30 30];
	imageAugmenter = imageDataAugmenter( ...
	'RandXReflection', true, ...
	'RandXTranslation', pixelRange, ...
	'RandYTranslation', pixelRange);
	
	augmented_image_data_train = augmentedImageDatastore(
	input_size(1:2), img_data_train, ...
	'DataAugmentation', imageAugmenter);
	
	augmented_image_data_validation = augmentedImageDatastore(
	input_size(1:2), img_data_validation);
	
	augmented_image_data_test = augmentedImageDatastore(
	input_size(1:2), img_data_test);
	\end{lstlisting}

	\noindent The reason why also the image for validation and for testing are augmented is because the method for augmentation (that is \texttt{augmentedImageDatastore}) automatically resize the image in order to fit the input size requested from AlexNet. In fact you can see that there is no \texttt{imageAugmenter} in the \texttt{augmentedImageDatastore} for validation and for test because it is used only for resizing, instead in the case of training images the same method perform both resizing and augmentation.
	
	\noindent For what concerns the CNN architecture only the last three layers of AlexNet have been removed and substituted with other three layer:
	
	\begin{lstlisting}
	net_layers = [
	original_layers
	fullyConnectedLayer(
		numberOfClasses,'WeightLearnRateFactor',20,'BiasLearnRateFactor',20)
	softmaxLayer
	classificationLayer]; 
	\end{lstlisting}

	\section{Final Results}
	\noindent At the end after some experiments the best architectures is the one in the two matlab scripts. Some hyper-parameters have been changed (for instance the initial learning rate, the weight learn rate factor, the bias learn rate factor ecc..), but at the end of the day the parameter that improve the performance is the maximum number of epochs, in fact increasing this parameter the training of the network require more time but it is more effective also because at every epoch the data are shuffled and so the presentation order of the images is different. The results obtained are the ones in figure \ref{img: trainingCnnTwoClassesFinalResult} and \ref{img: trainingCnnFourClassesFinalResult}. For what concern the test accuracy:
	\begin{itemize}
	\item Test Accuracy 2-classes problem: $97.08\%$
	\item Test Accuracy 4-classes problem: $80.31\%$
	\end{itemize}
	
	\begin{figure}[htbp]
		\centering
		\includegraphics[scale=0.31]{img/trainingCnnTwoClassesFinalResult.png}
		\caption{Final result for two-classes classification problem}
		\label{img: trainingCnnTwoClassesFinalResult}
	\end{figure}

	\begin{figure}[htbp]
		\centering
		\includegraphics[scale=0.31]{img/trainingCnnFourClassesFinalResult.png}
		\caption{Final result for four-classes classification problem}
		\label{img: trainingCnnFourClassesFinalResult}
	\end{figure}

	\noindent For what concern the confusion matrix the results in figure \ref{img: confusion2classes} and \ref{img: confusion4classes} have been obtained.
	
	\begin{figure}[htbp]
		\centering
		\includegraphics[scale=0.7]{img/confusion_2class.png}
		\caption{Confusion matrix for test images in 2-classes classification problem}
		\label{img: confusion2classes}
	\end{figure}

	\begin{figure}[htbp]
		\centering
		\includegraphics[scale=0.7]{img/confusion_4class.png}
		\caption{Confusion matrix for test images in 4-classes classification problem}
		\label{img: confusion4classes}
	\end{figure}

\end{document}